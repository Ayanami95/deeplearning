{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "name.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/chokkan/deeplearning/blob/master/notebook/name.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "bg5UQ01liJho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "25aa51c4-8d40-4631-fe4a-b088791e4627"
      },
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-07-22 01:09:46--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.32.80.22, 13.32.80.66, 13.32.80.97, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.32.80.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  4.96MB/s    in 0.6s    \n",
            "\n",
            "2018-07-22 01:09:47 (4.96 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF0dnFI8iPPR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "0ecb8ee4-fe2a-46a8-a0a3-9439a2096fb0"
      },
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\r\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J6sFMmTmiT3T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "import unicodedata\n",
        "\n",
        "# Alphabet [a-zA-Z .,;']\n",
        "alphabet = set(string.ascii_letters + \" .,;'\")\n",
        "\n",
        "def normalize(s):\n",
        "    # Apply canonical decomposition, and ignore non-alphabet symbols.\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s) if c in all_letters\n",
        "        )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_r6o4qMjzqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34bdc2d1-8c3c-4068-e8b4-864a0e50341b"
      },
      "cell_type": "code",
      "source": [
        "normalize('Ślusàrski')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Slusarski'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "KermR0rckh9z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import json\n",
        "import os\n",
        "\n",
        "data = {}\n",
        "srcs = glob.glob('data/names/*.txt')\n",
        "for src in srcs:\n",
        "    lang = os.path.basename(src)[:-4]\n",
        "    names = [normalize(s.strip('\\n')) for s in open(src)]\n",
        "    data[lang] = names\n",
        "    \n",
        "with open('names.json', 'w') as fo:\n",
        "    json.dump(data, fo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pe4UTXMEtwEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "12e9b623-bc55-4b35-fe4b-e0b106c6a497"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 484.0MB 20kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x5be9a000 @  0x7f56db78d1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.2.0 torch-0.4.0 torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "907yA2q5krl6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "data = json.load(open('names.json'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AzUXS0uYo5Bf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_vocabulary(data):\n",
        "    V = set()\n",
        "    for lang, names in data.items():\n",
        "        for name in names:\n",
        "            for c in name:\n",
        "                V.add(c)\n",
        "    return sorted(V)\n",
        "\n",
        "def build_labels(data):\n",
        "    return data.keys()\n",
        "\n",
        "def build_mapping(items):\n",
        "    M = {}\n",
        "    for item in items:\n",
        "        M.setdefault(item, len(M))\n",
        "    return M"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKWUzGxur0r6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "V = build_vocabulary(data)\n",
        "Vmap = build_mapping(V)\n",
        "Y = build_labels(data)\n",
        "Ymap = build_mapping(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IYkGRoNy2XYb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_dataset(data, Vmap, Ymap):\n",
        "    D = []\n",
        "    for lang, names in data.items():\n",
        "        for name in names:\n",
        "            D.append(([Vmap[c] for c in name], Ymap[lang]))\n",
        "    return D\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UySYe8jy3ZVy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = build_dataset(data, Vmap, Ymap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8Y-cSXlp3bvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5531841-70b3-4be2-9525-e3674e734e5b"
      },
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3, 30, 33, 40], 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "gSwvoRh93coD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3012abc5-757b-4daa-9969-69400528848c"
      },
      "cell_type": "code",
      "source": [
        "dataset[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([3, 30, 46, 29, 36, 29, 41], 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "uGphMMS-3fCj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "ff8d7a7c-1723-4eb5-c0f5-a913f4f99ba2"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "\n",
        "dtype = torch.float\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        output, hidden = self.rnn(input, hidden)\n",
        "        output = self.fc(output[-1])\n",
        "        return output\n",
        "    \n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)\n",
        "\n",
        "def label_to_tensor(l):\n",
        "    tensor = torch.zeros(1, dtype=torch.long)\n",
        "    tensor[0] = l\n",
        "    return tensor\n",
        "\n",
        "def seq_to_tensor(seq):\n",
        "    tensor = torch.zeros(len(seq), 1, len(V), dtype=dtype)\n",
        "    for i, l in enumerate(seq):\n",
        "        tensor[i][0][l] = 1\n",
        "    return tensor\n",
        "\n",
        "model = SimpleRNN(len(V), 128, len(Y))\n",
        "loss_fn = nn.CrossEntropyLoss(size_average=False)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for t in range(10):\n",
        "    train_loss = 0.\n",
        "    train_correct = 0\n",
        "    random.shuffle(dataset)\n",
        "    \n",
        "    # Training loop for every instance.\n",
        "    for (x, y) in dataset:\n",
        "        input = seq_to_tensor(x)\n",
        "        y = label_to_tensor(y)\n",
        "        hidden = model.initHidden()\n",
        "        \n",
        "        # Make predictions with the current parameters.\n",
        "        y_pred = model(input, hidden)\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        train_correct += (predicted == y).sum().item()\n",
        "        \n",
        "        # Compute the loss value.\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "        # Update the parameters.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    print(t, train_loss, float(train_correct) / len(dataset))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 33434.097751282156 0.5104612932151041\n",
            "1 26835.434397691162 0.6079007671615024\n",
            "2 23343.724399088707 0.6673806914416658\n",
            "3 21579.962789889745 0.6916907442462887\n",
            "4 20401.376432524296 0.7064860017933645\n",
            "5 19530.10094793685 0.7160007970509116\n",
            "6 18727.49529565179 0.7282056391351998\n",
            "7 17974.368901541908 0.73737172461891\n",
            "8 17453.31132408297 0.7436983162299492\n",
            "9 16904.26970829886 0.7527149546677294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xi_phdhW43nc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "name = 'Okazaki'\n",
        "x = seq_to_tensor([Vmap[c] for c in name])\n",
        "hidden = model.initHidden()\n",
        "y_pred = model(x, hidden)\n",
        "scores = []\n",
        "for lang, index in Ymap.items():\n",
        "    scores.append((lang, float(y_pred[0][index])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D9HJOcC4-Jwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "ab096cc0-f849-40f6-9759-4ff4a25a6562"
      },
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('French', -0.9161937236785889),\n",
              " ('Scottish', -2.1994919776916504),\n",
              " ('Italian', 0.7535350918769836),\n",
              " ('Portuguese', -1.298393726348877),\n",
              " ('English', -2.2725605964660645),\n",
              " ('Russian', 4.2647833824157715),\n",
              " ('Dutch', -0.439115047454834),\n",
              " ('German', -1.0358805656433105),\n",
              " ('Chinese', -1.7894344329833984),\n",
              " ('Arabic', 0.5966547131538391),\n",
              " ('Polish', 2.590327501296997),\n",
              " ('Japanese', 6.525790214538574),\n",
              " ('Czech', 2.0998802185058594),\n",
              " ('Irish', -0.326322078704834),\n",
              " ('Greek', -0.5004627704620361),\n",
              " ('Korean', -2.530669927597046),\n",
              " ('Spanish', -0.40204185247421265),\n",
              " ('Vietnamese', -1.2539485692977905)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "aqA6VAZ9EwUQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}